[toc]
# 妙语连珠
> 数据流
This is not rocket science, but it’s a real example where generators enabled an efficient and flexible solution to process databases as a stream of records, keeping memory usage low regardless of the size of the dataset.
# misc

## 相关章节

## chap 14
利用生成器函数解耦了读逻辑和写逻辑。当然，解耦二者最简单的方式是，把所有记录 读进内存，然后写入硬盘。可是这样并不可行，因为数据集很大。而使用生成器的话，可 以交叉读写，因此这个脚本可以处理任意大小的文件.
使用生成器处理数 据库时，我们把记录看成数据流，这样消耗的内存量最低，而且不管数据有多大都能处 理。只要管理着大型数据集，都有可能在实践中找到机会使用生成器。
By leveraging generator functions, I was able to decouple the reading from the writ‐ ing. Of course, the simplest way to decouple them would be to read all records to memory, then write them to disk. But that was not a viable option because of the size of the datasets. Using generators, the reading and writing is interleaved, so the script can process files of any size. This is not rocket science, but it’s a real example where generators enabled an efficient and flexible solution to process databases as a stream of records, keeping memory usage low regardless of the size of the dataset.